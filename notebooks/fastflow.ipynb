{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqvA5JmYVUGK"
      },
      "source": [
        "## Setting up the Working Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openvinotoolkit/anomalib.git\n",
        "%cd anomalib\n",
        "%pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S0w-G01IcSJ1",
        "outputId": "9cfc2acb-8a43-4a95-cef9-5b36c28e5177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anomalib'...\n",
            "remote: Enumerating objects: 27530, done.\u001b[K\n",
            "remote: Counting objects: 100% (755/755), done.\u001b[K\n",
            "remote: Compressing objects: 100% (535/535), done.\u001b[K\n",
            "remote: Total 27530 (delta 224), reused 714 (delta 210), pack-reused 26775\u001b[K\n",
            "Receiving objects: 100% (27530/27530), 1.50 GiB | 17.49 MiB/s, done.\n",
            "Resolving deltas: 100% (15159/15159), done.\n",
            "/content/anomalib\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/anomalib\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops>=0.3.2\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia<0.6.10,>=0.6.6\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl (569 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.1.1\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<1.10.0,>=1.7.0\n",
            "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 KB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<=0.6.12,>=0.5.4\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.4.3 in /usr/local/lib/python3.9/dist-packages (from anomalib==0.5.0.dev0) (3.5.3)\n",
            "Collecting av>=10.0.0\n",
            "  Downloading av-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.9/dist-packages (from anomalib==0.5.0.dev0) (0.4.0)\n",
            "Collecting jsonargparse[signatures]>=4.3\n",
            "  Downloading jsonargparse-4.20.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from anomalib==0.5.0.dev0) (1.3.5)\n",
            "Requirement already satisfied: opencv-python>=4.5.3.56 in /usr/local/lib/python3.9/dist-packages (from anomalib==0.5.0.dev0) (4.6.0.66)\n",
            "Requirement already satisfied: albumentations>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from anomalib==0.5.0.dev0) (1.2.1)\n",
            "Collecting freia>=0.2\n",
            "  Downloading FrEIA-0.2.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics==0.10.3\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 KB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (2.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from imgaug==0.4.0->anomalib==0.5.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics==0.10.3->anomalib==0.5.0.dev0) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics==0.10.3->anomalib==0.5.0.dev0) (23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations>=1.1.0->anomalib==0.5.0.dev0) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations>=1.1.0->anomalib==0.5.0.dev0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations>=1.1.0->anomalib==0.5.0.dev0) (4.7.0.72)\n",
            "Collecting typeshed-client>=2.1.0\n",
            "  Downloading typeshed_client-2.2.0-py3-none-any.whl (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m551.6/551.6 KB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser>=0.15\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4.3->anomalib==0.5.0.dev0) (4.39.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4.3->anomalib==0.5.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4.3->anomalib==0.5.0.dev0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4.3->anomalib==0.5.0.dev0) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4.3->anomalib==0.5.0.dev0) (2.8.2)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->anomalib==0.5.0.dev0) (2022.7.1)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (2023.3.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm<=0.6.12,>=0.5.4->anomalib==0.5.0.dev0) (0.14.1+cu116)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (2.25.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations>=1.1.0->anomalib==0.5.0.dev0) (1.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib==0.5.0.dev0) (3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib==0.5.0.dev0) (2023.2.28)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib==0.5.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.3->anomalib==0.5.0.dev0) (5.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm<=0.6.12,>=0.5.4->anomalib==0.5.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=1.4.0->typeshed-client>=2.1.0->jsonargparse[signatures]>=4.3->anomalib==0.5.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.1.0->anomalib==0.5.0.dev0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.1.0->anomalib==0.5.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib==0.5.0.dev0) (4.0.0)\n",
            "Building wheels for collected packages: anomalib, freia, antlr4-python3-runtime\n",
            "  Building wheel for anomalib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anomalib: filename=anomalib-0.5.0.dev0-py3-none-any.whl size=302308 sha256=3f83319cb351cb4cd1863de91324b3551268ef923f95ba9a772a112067a02ac2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7hr15ztr/wheels/fc/0d/e5/c6f1d073dc9a8f8f7800ee8adb4e83202f909f72038e5982c8\n",
            "  Building wheel for freia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for freia: filename=FrEIA-0.2-py3-none-any.whl size=42782 sha256=3148a56d921e184a21f734ef93a48bb8a9972785e96bc716c2bbd567ee79d95f\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/a1/a2/86042a265a1955f22241bad323984cdbec939c785008530e6c\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=21659a6bb0ffc9512344c4c42964af5b7ce4184748d2b538efff168755f3a290\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "Successfully built anomalib freia antlr4-python3-runtime\n",
            "Installing collected packages: av, antlr4-python3-runtime, omegaconf, multidict, lightning-utilities, jsonargparse, frozenlist, einops, docstring-parser, charset-normalizer, async-timeout, yarl, typeshed-client, torchmetrics, kornia, huggingface-hub, freia, aiosignal, timm, aiohttp, pytorch-lightning, anomalib\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 anomalib-0.5.0.dev0 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 av-10.0.0 charset-normalizer-3.1.0 docstring-parser-0.15 einops-0.6.0 freia-0.2 frozenlist-1.3.3 huggingface-hub-0.13.1 jsonargparse-4.20.0 kornia-0.6.9 lightning-utilities-0.8.0 multidict-6.0.4 omegaconf-2.3.0 pytorch-lightning-1.9.4 timm-0.6.12 torchmetrics-0.10.3 typeshed-client-2.2.0 yarl-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git.repo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPrCZjy-cz8Y",
        "outputId": "eb9562ae-390a-4d0a-8bab-91043afcf6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git.repo\n",
            "  Downloading git_repo-1.10.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting github3.py<1.0.0\n",
            "  Downloading github3.py-0.9.6-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-gitlab>=1.0.0\n",
            "  Downloading python_gitlab-3.13.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 KB\u001b[0m \u001b[31m994.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gogs-client>=1.0.3\n",
            "  Downloading gogs_client-1.0.6-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from git.repo) (2.8.2)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GitPython>=2.1.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting progress\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybitbucket-fork>=0.12.2\n",
            "  Downloading pybitbucket_fork-0.12.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from git.repo) (4.9.2)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.9/dist-packages (from github3.py<1.0.0->git.repo) (2.25.1)\n",
            "Collecting uritemplate.py>=0.2.0\n",
            "  Downloading uritemplate.py-3.0.2-py2.py3-none-any.whl (4.9 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from gogs-client>=1.0.3->git.repo) (0.16.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from gogs-client>=1.0.3->git.repo) (22.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pybitbucket-fork>=0.12.2->git.repo) (1.15.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.9/dist-packages (from pybitbucket-fork>=0.12.2->git.repo) (3.2.2)\n",
            "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.9/dist-packages (from pybitbucket-fork>=0.12.2->git.repo) (1.3.1)\n",
            "Requirement already satisfied: uritemplate in /usr/local/lib/python3.9/dist-packages (from pybitbucket-fork>=0.12.2->git.repo) (4.1.1)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.18.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.8/136.8 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting voluptuous\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Collecting requests-toolbelt>=0.10.1\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.0->github3.py<1.0.0->git.repo) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.0->github3.py<1.0.0->git.repo) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.0->github3.py<1.0.0->git.repo) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.0->github3.py<1.0.0->git.repo) (2.10)\n",
            "Building wheels for collected packages: pybitbucket-fork, docopt, progress\n",
            "  Building wheel for pybitbucket-fork (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybitbucket-fork: filename=pybitbucket_fork-0.12.2-py3-none-any.whl size=34078 sha256=1370f84d2010270a07c5aa0b4a189f09453a65568336218641a01792e2f8e7e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2c/a5/7e22bfede6516aa9e9dff96475b26f701098ef57135002debd\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=17bfebbe0e9cceeea328686289d6ef0265fa67f4a931e7a161e6b17268062dee\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9630 sha256=16226d6ad9c42c60a066ab14d3814f96b2c4ba4aeddab6a0ee2b55d08b14709d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/9b/0a/a78ff56725af3ef70792f9ed0f8dbbc4c0315edc62cbc4a6b8\n",
            "Successfully built pybitbucket-fork docopt progress\n",
            "Installing collected packages: voluptuous, progress, docopt, uritemplate.py, smmap, simplejson, requests-toolbelt, gogs-client, github3.py, gitdb, python-gitlab, pybitbucket-fork, GitPython, git.repo\n",
            "Successfully installed GitPython-3.1.31 docopt-0.6.2 git.repo-1.10.3 gitdb-4.0.10 github3.py-0.9.6 gogs-client-1.0.6 progress-1.6 pybitbucket-fork-0.12.2 python-gitlab-3.13.0 requests-toolbelt-0.10.1 simplejson-3.18.3 smmap-5.0.0 uritemplate.py-3.0.2 voluptuous-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpHfIbu7VUGP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from functools import partial, update_wrapper\n",
        "from pathlib import Path\n",
        "from types import MethodType\n",
        "from typing import Any\n",
        "\n",
        "from git.repo import Repo\n",
        "\n",
        "current_directory = Path.cwd()\n",
        "if current_directory.name == \"200_models\":\n",
        "    # On the assumption that, the notebook is located in\n",
        "    #   ~/anomalib/notebooks/100_datamodules/\n",
        "    root_directory = current_directory.parent.parent\n",
        "elif current_directory.name == \"anomalib\":\n",
        "    # This means that the notebook is run from the main anomalib directory.\n",
        "    root_directory = current_directory\n",
        "else:\n",
        "    # Otherwise, we'll need to clone the anomalib repo to the `current_directory`\n",
        "    repo = Repo.clone_from(url=\"https://github.com/openvinotoolkit/anomalib.git\", to_path=current_directory)\n",
        "    root_directory = current_directory / \"anomalib\"\n",
        "\n",
        "os.chdir(root_directory)\n",
        "dataset_root = root_directory / \"datasets\" / \"MVTec\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Lra16u2iVUGQ"
      },
      "source": [
        "\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eco-WPlaeY_F",
        "outputId": "54a526c3-600d-4922-9e6e-cf50eb066e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.11-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.25.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (57.4.0)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=5ada8c0ac95a391c93bbe777fd188861893a32d79c1991cf6398fe9c9d2f3857\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, appdirs, setproctitle, sentry-sdk, docker-pycreds, wandb\n",
            "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.16.0 setproctitle-1.3.2 wandb-0.13.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y6wW8sJfVUGR"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.adam import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from anomalib.data import InferenceDataset, TaskType\n",
        "from anomalib.data.mvtec import MVTec\n",
        "from anomalib.models.fastflow.lightning_model import Fastflow\n",
        "from anomalib.post_processing import (\n",
        "    NormalizationMethod,\n",
        "    ThresholdMethod,\n",
        "    superimpose_anomaly_map,\n",
        ")\n",
        "from anomalib.pre_processing.transforms import Denormalize\n",
        "from anomalib.utils.callbacks import (\n",
        "    ImageVisualizerCallback,\n",
        "    MetricsConfigurationCallback,\n",
        "    MetricVisualizerCallback,\n",
        "    PostProcessingConfigurationCallback,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "yX_q78fIVUGS"
      },
      "source": [
        "## Data Module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lc98rl0VUGT"
      },
      "outputs": [],
      "source": [
        "task = TaskType.SEGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d3f7tzR9VUGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a924103-3c21-4d52-b7ec-37a4bdc43da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mvtec:   4%|▍         | 205M/5.26G [00:28<14:14, 5.92MB/s]"
          ]
        }
      ],
      "source": [
        "datamodule = MVTec(\n",
        "    root=dataset_root,\n",
        "    category=\"bottle\",\n",
        "    image_size=256,\n",
        "    train_batch_size=32,\n",
        "    eval_batch_size=32,\n",
        "    num_workers=8,\n",
        "    task=task,\n",
        ")\n",
        "datamodule.prepare_data()\n",
        "datamodule.setup()\n",
        "i, data = next(enumerate(datamodule.test_dataloader()))\n",
        "print(f'Image Shape: {data[\"image\"].shape} Mask Shape: {data[\"mask\"].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (datamodule.eval_batch_size)"
      ],
      "metadata": {
        "id": "pzAGQW-8haX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BePDighaVUGU"
      },
      "source": [
        "## FastFlow Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PDFov6_XVUGU"
      },
      "outputs": [],
      "source": [
        "Fastflow??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x33DnVKSVUGV"
      },
      "outputs": [],
      "source": [
        "model = Fastflow(input_size=(256, 256), backbone=\"resnet18\", flow_steps=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-x5sAHEfVUGV"
      },
      "source": [
        "Depending on the `training` mode, `model` returns two different outputs. If the model is in `training` mode, it returns the hidden variable and the log of the jacobian, based on the feature maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "27e_3MlYVUGW"
      },
      "outputs": [],
      "source": [
        "model.training = True\n",
        "train_output = model(data[\"image\"])\n",
        "hidden_variables, log_jacobian = train_output\n",
        "print(f\"Hidden Variable Shape: {hidden_variables[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_wUleyKCVUGX"
      },
      "source": [
        "During the test/inference mode, the model returns an anomaly heatmap localizing the anomalous regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "btcV1sdMVUGX"
      },
      "outputs": [],
      "source": [
        "model.model.training = False\n",
        "anomaly_map = model(data[\"image\"])\n",
        "print(f\"Anomaly Map Shape: {anomaly_map.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "79NElEH9VUGY"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "`LightningModule` has `configure_optimizer` method that returns the optimizer object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DjPrSan8VUGZ"
      },
      "outputs": [],
      "source": [
        "def configure_optimizers(lightning_module: LightningModule, optimizer: Optimizer) -> Any:  # pylint: disable=W0613,W0621\n",
        "    \"\"\"Override to customize the LightningModule.configure_optimizers` method.\"\"\"\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "optimizer = Adam(params=model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-5)\n",
        "fn = partial(configure_optimizers, optimizer=optimizer)\n",
        "update_wrapper(fn, configure_optimizers)  # necessary for `is_overridden`\n",
        "model.configure_optimizers = MethodType(fn, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "77VARPDwVUGZ"
      },
      "source": [
        "## Callbacks\n",
        "\n",
        "To train the model properly, we will to add some other \"non-essential\" logic such as saving the weights, early-stopping, normalizing the anomaly scores and visualizing the input/output images. To achieve these we use `Callbacks`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Si8ZM8CjVUGZ"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    MetricsConfigurationCallback(\n",
        "        task=task,\n",
        "        image_metrics=[\"AUROC\"],\n",
        "        pixel_metrics=[\"AUROC\"],\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        mode=\"max\",\n",
        "        monitor=\"pixel_AUROC\",\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"pixel_AUROC\",\n",
        "        mode=\"max\",\n",
        "        patience=3,\n",
        "    ),\n",
        "    PostProcessingConfigurationCallback(\n",
        "        normalization_method=NormalizationMethod.MIN_MAX,\n",
        "        threshold_method=ThresholdMethod.ADAPTIVE,\n",
        "    ),\n",
        "    ImageVisualizerCallback(mode=\"full\", task=task, image_save_path=\"./results/images\"),\n",
        "    MetricVisualizerCallback(mode=\"full\", task=task, image_save_path=\"./results/images\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WK0Zx6XwVUGa"
      },
      "source": [
        "## Training\n",
        "\n",
        "\n",
        "The final component to train the model is `pytorch_lightning` `Trainer` object, which handles train/test/predict pipeline. Let's create the trainer object to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ou4tksRTVUGa"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
        "    devices=1,\n",
        "    max_epochs=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-CDo63TnDc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xBYg1SHkVUGa"
      },
      "outputs": [],
      "source": [
        "trainer.fit(datamodule=datamodule, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5EujPTxOVUGa"
      },
      "source": [
        "The training has finished after 22 epochs. This is because, we set the `EarlyStopping` criteria with a patience of 3, which terminated the training after `pixel_AUROC` stopped improving. If we increased the `patience`, the training would continue further.\n",
        "\n",
        "## Testing\n",
        "\n",
        "Now that we trained the model, we could test the model to check the overall performance on the test set. We will also be writing the output of the test images to a file since we set `VisualizerCallback` in `callbacks`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y8_in08cVUGb"
      },
      "outputs": [],
      "source": [
        "trainer.test(datamodule=datamodule, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "C3iCA0xZVUGb"
      },
      "source": [
        "`trainer.test` returns the `pixel_AUROC` and `image_AUROC` results. We could also find the saved output in `images` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "69mAgcj-VUGb"
      },
      "outputs": [],
      "source": [
        "!ls results/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hPOzuKqZVUGb"
      },
      "source": [
        "## Inference\n",
        "\n",
        " we could infer the model on an individual image or folder of images. Anomalib has an `InferenceDataset` to let you create an inference dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TZhWXDaIVUGb"
      },
      "outputs": [],
      "source": [
        "inference_dataset = InferenceDataset(path=dataset_root / \"wood/test/color/000.png\", image_size=(256, 256))\n",
        "inference_dataloader = DataLoader(dataset=inference_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V5usrn3AVUGc"
      },
      "source": [
        "We could utilize `Trainer`'s `predict` method to infer, and get the outputs to visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VF_OZCjxVUGc"
      },
      "outputs": [],
      "source": [
        "predictions = trainer.predict(model=model, dataloaders=inference_dataloader)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "a2IH7fa1VUGc"
      },
      "source": [
        "`predictions` contain image, anomaly maps, predicted scores, labels and masks. These are all stored in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yjpF-RB6VUGc"
      },
      "outputs": [],
      "source": [
        "print(predictions.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tZb5WJfWVUGc"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    f'Image Shape: {predictions[\"image\"].shape},\\n'\n",
        "    'Anomaly Map Shape: {predictions[\"anomaly_maps\"].shape}, \\n'\n",
        "    'Predicted Mask Shape: {predictions[\"pred_masks\"].shape}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TNwvyLoNVUGd"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UkJ3zVmIVUGd"
      },
      "source": [
        "post processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hE5dSVTeVUGd"
      },
      "outputs": [],
      "source": [
        "image = predictions[\"image\"][0]\n",
        "image = Denormalize()(image)\n",
        "print(f\"Image Shape: {image.shape}\\n Min Pixel: {image.min()} \\n Max Pixel: {image.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qS_WSkUoVUGd"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7YPxTuY9VUGe"
      },
      "source": [
        "The second output of the predictions is the anomaly map. As can be seen above, it's also a torch tensor and of size `torch.Size([1, 1, 256, 256])`. We therefore need to convert it to numpy and squeeze the dimensions to make it `256x256` output to visualize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FMbHPKvkVUGe"
      },
      "outputs": [],
      "source": [
        "anomaly_map = predictions[\"anomaly_maps\"][0]\n",
        "anomaly_map = anomaly_map.cpu().numpy().squeeze()\n",
        "plt.imshow(anomaly_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FDcskwa0VUGe"
      },
      "source": [
        "We could superimpose (overlay) the anomaly map on top of the original image to get a heat map. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d0xOvjkHVUGe"
      },
      "outputs": [],
      "source": [
        "heat_map = superimpose_anomaly_map(anomaly_map=anomaly_map, image=image, normalize=True)\n",
        "plt.imshow(heat_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "l1qwD5QbVUGe"
      },
      "source": [
        "`predictions` also contains prediction scores and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eZ6DZIFWVUGe"
      },
      "outputs": [],
      "source": [
        "pred_score = predictions[\"pred_scores\"][0]\n",
        "pred_labels = predictions[\"pred_labels\"][0]\n",
        "print(pred_score, pred_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LzWb9RpFVUGg"
      },
      "source": [
        "The last part of the predictions is the mask that is predicted by the model. This is a boolean mask containing True/False for the abnormal/normal pixels, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iXRSwRnuVUGg"
      },
      "outputs": [],
      "source": [
        "pred_masks = predictions[\"pred_masks\"][0].squeeze().cpu().numpy()\n",
        "plt.imshow(pred_masks)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "anomalib",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f26beec5b578f06009232863ae217b956681fd13da2e828fa5a0ecf8cf2ccd29"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}